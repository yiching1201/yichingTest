---
sidebar_position: 1
---

# PE1100N


## 1. Flash Image

PE1100N only support flash image via Ubuntu and doesn't support flash image via Windows.

### 1.1 Recovery Mode
1. **System Requirement**

    • Linux Host Computer (x86 Ubuntu 18.04 and above)

    • Micro USB cable

2. **Enter Force Recovery Mode**   
For PE1100N Box, the Flash Port is number ❷, and the Force Recovery Button is number ❹.
![234836537-a91d0518-55ef-4694-a575-fd1345164753](https://user-images.githubusercontent.com/97945168/236100307-e4562179-e662-424f-9853-5b67d3f4834f.png)   

Please perform the following steps to force the PE1100N to enter force recovery mode:   

**[PE1100N]**
   
   1. Power off the PE1100N and remove the power cable.
   2. Connect Host Computer and PE1100N Flash Port (number ❷) with Micro USB cable.
   3. Press and hold the Force Recovery Button (number ❹).
   4. Connect the power cable and Power ON the PE1100N.
   5. After 3s release the Force Recovery Button.

**[Host Computer]**

On the Linux host PC, open a Terminal window and enter the command `lsusb`. If the returned content has one of the following outputs according to the Jetson SoM you use, then the board is in force recovery mode.

![234836868-50478e57-027e-4784-a458-51d325f5b256](https://user-images.githubusercontent.com/97945168/236101253-dd90c67d-2ceb-48a5-83b6-02b57e710244.png)

• For Orin NX 16GB: 0955:7323 NVidia Corp   
• For Orin NX 8GB: 0955:7423 NVidia Corp   
• For Orin Nano 8GB: 0955:7523 NVidia Corp   
• For Orin Nano 4GB: 0955:7623 NVidia Corp   


&nbsp;

### 1.2 Flash Image

**[Host Computer]**
1. Extract BSP file on Host Computer.

   BSP file example :

| System  | File Name |
| ------------- | ------------- |
| PE1100N Orin Nano 4GB  | PE1100N Orin Nano 4GB JetPack x.x.x Image Vx.x.x  |
| PE1100N Orin Nano 8GB  | PE1100N Orin Nano 8GB JetPack x.x.x Image Vx.x.x  |
| PE1100N Orin NX 16GB  | PE1100N Orin NX 16GB JetPack x.x.x Image Vx.x.x  |

Download Link : https://www.asus.com/networking-iot-servers/aiot-industrial-solutions/embedded-computers-edge-ai-systems/pe1100n/helpdesk_download?model2Name=PE1100N

```
sudo tar xvpf PE1100N_JXANS_Orin-NX-16GB_JetPack-ssd-5.1.1_L4T-35.3.1_v0.1.3-debug-20230503.tar.gz
```

2. Change folder

```
cd mfi_PE110xxxxxxxx  
sudo ./tools/kernel_flash/l4t_initrd_flash.sh --erase-all --flash-only --showlogs --network usb0
```

3. Flashing the image takes around 15 minutes.

**[PE1100N]**   
   After 15 minutes, PE1100N will auto reboot.

>NOTE :
> 1. Do not use a USB Hub between Host Computer and PE1100N.
> 2. You can know the process of flashing image from “mfi_PE1100N-orin/initrdlog”.

&nbsp;


## 2. Build Image

### 2.1 Jetpack 6.0 image

1. Installation Prerequisites
```
$ sudo apt update
$ sudo apt install -y apt-utils bc build-essential cpio curl \
device-tree-compiler expect gawk gdisk git kmod liblz4-tool libssl-dev \
locales parted python python3 qemu-user-static rsync \
software-properties-common sudo time tzdata udev unzip wget zip \
nfs-kernel-server uuid-runtime
```
2. Download and prepare the Linux_for_Tegra source code
```
$ wget https://developer.nvidia.com/downloads/embedded/l4t/r36_release_v3.0/release/jetson_linux_r36.3.0_aarch64.tbz2
$ tar xf jetson_linux_r36.3.0_aarch64.tbz2
```
3. Download and prepare sample root file system
```
$ wget https://developer.nvidia.com/downloads/embedded/l4t/r36_release_v3.0/release/tegra_linux_sample-root-filesystem_r36.3.0_aarch64.tbz2
$ sudo tar xpf tegra_linux_sample-root-filesystem_r36.3.0_aarch64.tbz2 -C Linux_for_Tegra/rootfs/
```
4. Sync the source code for compiling
```
$ cd Linux_for_Tegra/source/
$ ./source_sync.sh -t jetson_36.3
```
If the following error occurs, please wait for Nvidia to provide a fix.
![NV_fatal_error](https://github.com/user-attachments/assets/7a2b4746-4175-409c-8fc4-a8b391f18fa3)

reference:
https://forums.developer.nvidia.com/t/unable-to-connect-to-nv-tegra-nvidia-com/334353

5. Download the patch file for PE1100N

   https://drive.google.com/file/d/12wBWT0YSfkDncw0JbIJu2hYsKAeRnzTu/view?usp=sharing

6. Overwrite the original source code by patch files
```
$ cd ../..
# Copy the PE1100N_r3630_patch.tar.gz to this folder.
$ tar zxf PE1100N_r3630_patch.tar.gz
$ sudo cp -r PE1100N_r3630_patch/Linux_for_Tegra/* Linux_for_Tegra/
```
   **For Nano 4G only**
   ```
   $ sudo cp PE1100N_r3630_patch/nano_4g_patch/chip_info.bin_bak Linux_for_Tegra/bootloader 
   ```

7. Apply necessary changes to rootfs
```
$ cd Linux_for_Tegra
$ sudo ./apply_binaries.sh
```
8. Download and install the toolchain
```
$ wget https://developer.nvidia.com/downloads/embedded/l4t/r36_release_v3.0/toolchain/aarch64--glibc--stable-2022.08-1.tar.bz2
$ sudo tar xf aarch64--glibc--stable-2022.08-1.tar.bz2 -C /opt
$ rm aarch64--glibc--stable-2022.08-1.tar.bz2
```
9. Build the kernel
```
$ cd source
$ export ARCH=arm64
$ export CROSS_COMPILE=/opt/aarch64--glibc--stable-2022.08-1/bin/aarch64-linux-
$ ./nvbuild_asus.sh
```
10. Install new kernel dtbs and kernel modules
```
$ ./do_copy.sh
$ export INSTALL_MOD_PATH=`realpath ../rootfs/`
$ ./nvbuild_asus.sh -i
$ cd ..
```
11. Pre-install JetPack SDK (optional)
```
$ sudo sed -i "s/<SOC>/t234/g" rootfs/etc/apt/sources.list.d/nvidia-l4t-apt-source.list
$ sudo cp /usr/bin/qemu-aarch64-static rootfs/usr/bin/
$ sudo mount --bind /sys ./rootfs/sys
$ sudo mount --bind /dev ./rootfs/dev
$ sudo mount --bind /dev/pts ./rootfs/dev/pts
$ sudo mount --bind /proc ./rootfs/proc
$ sudo chroot rootfs
# apt update
# apt install -y nvidia-jetpack
# apt clean
# exit
$ sudo umount ./rootfs/sys
$ sudo umount ./rootfs/dev/pts
$ sudo umount ./rootfs/dev
$ sudo umount ./rootfs/proc
$ sudo rm rootfs/usr/bin/qemu-aarch64-static
```
12. Flash the device

* Orin NX 16G
```
$ sudo BOARDID=3767 BOARDSKU=0000 ./tools/kernel_flash/l4t_initrd_flash.sh --external-device nvme0n1p1 -c tools/kernel_flash/flash_l4t_t234_nvme.xml -p "-c bootloader/generic/cfg/flash_t234_qspi.xml" --showlogs --network usb0 PE1100N-orin internal
```
* Orin NX 8G
```
$ sudo BOARDID=3767 BOARDSKU=0001 ./tools/kernel_flash/l4t_initrd_flash.sh --external-device nvme0n1p1 -c tools/kernel_flash/flash_l4t_t234_nvme.xml -p "-c bootloader/generic/cfg/flash_t234_qspi.xml" --showlogs --network usb0 PE1100N-orin internal
```
* Orin Nano 8G
```
$ sudo BOARDID=3767 BOARDSKU=0003 ./tools/kernel_flash/l4t_initrd_flash.sh --external-device nvme0n1p1 -c tools/kernel_flash/flash_l4t_t234_nvme.xml -p "-c bootloader/generic/cfg/flash_t234_qspi.xml" --showlogs --network usb0 PE1100N-orin internal
```
* Orin Nano 4G
```
$ sudo BOARDID=3767 BOARDSKU=0004 ./tools/kernel_flash/l4t_initrd_flash.sh --external-device nvme0n1p1 -c tools/kernel_flash/flash_l4t_t234_nvme.xml -p "-c bootloader/generic/cfg/flash_t234_qspi.xml" --showlogs --network usb0 PE1100N-orin internal
$ sudo rm bootloader/chip_info.bin_bak
```
&nbsp;

### 2.2 Jetpack 6.2 image

1. Installing Prerequisites
```
$ sudo apt update
$ sudo apt install -y apt-utils bc build-essential cpio curl \
device-tree-compiler expect gawk gdisk git kmod liblz4-tool libssl-dev \
locales parted python3 qemu-user-static rsync \
software-properties-common sudo time tzdata udev unzip wget zip \
nfs-kernel-server uuid-runtime
```

2. Download and prepare the Linux_for_Tegra source code
```
$ wget https://developer.nvidia.com/downloads/embedded/l4t/r36_release_v4.3/release/Jetson_Linux_r36.4.3_aarch64.tbz2
$ tar xf Jetson_Linux_r36.4.3_aarch64.tbz2
```

3. Download and prepare sample root file system
```
$ wget https://developer.nvidia.com/downloads/embedded/l4t/r36_release_v4.3/release/Tegra_Linux_Sample-Root-Filesystem_r36.4.3_aarch64.tbz2
$ sudo tar xpf Tegra_Linux_Sample-Root-Filesystem_r36.4.3_aarch64.tbz2 -C Linux_for_Tegra/rootfs/
```

4. Sync the source code for compiling
```
$ cd Linux_for_Tegra/source/
$ ./source_sync.sh -t jetson_36.4.3
```

* If the following error occurs, please wait for Nvidia to fix it.

   ![圖片1](https://github.com/user-attachments/assets/e53d3db9-45d7-487c-bf5f-b51f96e5675a)

   Reference: https://forums.developer.nvidia.com/t/unable-to-connect-to-nv-tegra-nvidia-com/334353

5. Download the patch file for PE1100N

   https://drive.google.com/file/d/14sQxWWBMq40wqrE8U0H9MEENZv54nCK4/view?usp=sharing

   Copy it in the same location as the Linux_for_Tegra folder.

   ![圖片2](https://github.com/user-attachments/assets/7d5b2eee-9ae4-4e5f-b904-a296c93eef16)

6. Overwrite the original source code by patch files
```
$ cd ../..
$ tar zxf PE1100N_v2.0.11_patch.tar.gz
$ sudo cp -r PE1100N_v2.0.11_patch/Linux_for_Tegra/* Linux_for_Tegra/
```

7. Apply necessary changes to rootfs
```
$ cd Linux_for_Tegra
$ sudo ./apply_binaries.sh
```

8. Download and install the toolchain
```
$ wget https://developer.nvidia.com/downloads/embedded/l4t/r36_release_v3.0/toolchain/aarch64--glibc--stable-2022.08-1.tar.bz2
$ sudo tar xf aarch64--glibc--stable-2022.08-1.tar.bz2 -C /opt
$ rm aarch64--glibc--stable-2022.08-1.tar.bz2
```

9. Build the kernel
```
$ cd source
$ export ARCH=arm64
$ export CROSS_COMPILE=/opt/aarch64--glibc--stable-2022.08-1/bin/aarch64-linux-
$ ./nvbuild_asus.sh
```

10. Install new kernel dtbs and kernel modules
```
$ ./do_copy.sh
$ export INSTALL_MOD_PATH=`realpath ../rootfs/`
$ ./nvbuild_asus.sh -i
$ cd ..
```

11. Pre-install JetPack SDK (optional)
```
$ sudo sed -i "s/<SOC>/t234/g" rootfs/etc/apt/sources.list.d/nvidia-l4t-apt-source.list
$ sudo cp /usr/bin/qemu-aarch64-static rootfs/usr/bin/
$ sudo mount --bind /sys ./rootfs/sys
$ sudo mount --bind /dev ./rootfs/dev
$ sudo mount --bind /dev/pts ./rootfs/dev/pts
$ sudo mount --bind /proc ./rootfs/proc
$ sudo chroot rootfs
# apt update
# apt install -y nvidia-jetpack
# apt clean
# exit
$ sudo umount ./rootfs/sys
$ sudo umount ./rootfs/dev/pts
$ sudo umount ./rootfs/dev
$ sudo umount ./rootfs/proc
$ sudo rm rootfs/usr/bin/qemu-aarch64-static
```

12. Build the SSD image
```
$ sudo build.sh
```

   * Select the SOM you are using.

   ![圖片3](https://github.com/user-attachments/assets/45651294-8d69-4150-b722-1a2e1a53c154)

   * Build success will be shown as in the image below.

   ![圖片4](https://github.com/user-attachments/assets/8923660a-579c-4aaf-9224-67630bd5dd54)

   * The image will be generated in the mfi_PE1100N-orin folder and will be packaged as mfi_PE1100N-orin.tar.gz.

   ![圖片5](https://github.com/user-attachments/assets/fe0e4328-67ee-4631-9d5d-9d064db3ebfd)

13. Flash image to device

Installing the flash requirements
```
$ sudo ./tools/l4t_flash_prerequisites.sh
```

Set up the device in recovery mode, then flash the image.
```
$ cd mfi_PE1100N-orin
$ sudo ./tools/kernel_flash/l4t_initrd_flash.sh --erase-all --flash-only --showlogs --network usb0
```

&nbsp;

## 3. Upgrade to Jetpack 6.1

1. Please make sure your OS is Jetpack 6.0
```
$ cat /etc/nv_tegra_release
```
![123](https://github.com/user-attachments/assets/d090a596-fdd4-474a-bdbc-5d2a167b104d)

2. Add the R36.4/JP 6.1 
```
$ echo "deb https://repo.download.nvidia.com/jetson/common r36.4 main" | sudo tee -a /etc/apt/sources.list.d/nvidia-l4t-apt-source.list
$ echo "deb https://repo.download.nvidia.com/jetson/t234 r36.4 main" | sudo tee -a /etc/apt/sources.list.d/nvidia-l4t-apt-source.list
```
3. Update the apt
```
$ sudo apt-get update
```

4. Install Jetpack compute components
```
$ sudo apt-get install nvidia-jetpack
```

5. Remove the R36.4/JP 6.1 repo to avoid installing **nvidia-l4t bsp** packages accidentally later  
    **Important**  
    Do not use **apt-get upgrade** because that will upgrade L4T packages too

**For more details, please follow the link below from NVIDIA official website.**  
https://docs.nvidia.com/jetson/archives/jetpack-archived/jetpack-61/install-setup/index.html#upgradable-compute-stack

&nbsp;

## 4. Backup and Restore OS image

>For Jetpack 5 & Jetpack 6

**Prerequisites**   
   a. Ubuntu Host PC 20.04 or 22.04   
   b. Micro USB cable   

1. Installing Prerequisites
```
$ sudo apt update
$ sudo apt install -y abootimg binfmt-support binutils cpio cpp device-tree-compiler dosfstools \
iproute2 iputils-ping lbzip2 libxml2-utils netcat nfs-kernel-server openssl python3-yaml qemu-user-static \
rsync sshpass udev uuid-runtime whois xmlstarlet zstd lz4 chrpath diffstat xxd wget bc
```

2. Download and prepare the Nvidia Jetpack SDK
```
$ wget https://developer.nvidia.com/downloads/embedded/l4t/r36_release_v4.3/release/Jetson_Linux_r36.4.3_aarch64.tbz2
$ tar xf Jetson_Linux_r36.4.3_aarch64.tbz2
```
   After extracting the Jetson_Linux_r36.4.3_aarch64.tbz2 file, you will see a Linux_for_Tegra folder.   

   ![圖片1](https://github.com/user-attachments/assets/d34f005c-3535-4c72-9368-af68aa5a5283)

3. Download and prepare sample root file system
```
$ wget https://developer.nvidia.com/downloads/embedded/l4t/r36_release_v4.3/release/Tegra_Linux_Sample-Root-Filesystem_r36.4.3_aarch64.tbz2
$ sudo tar xpf Tegra_Linux_Sample-Root-Filesystem_r36.4.3_aarch64.tbz2 -C Linux_for_Tegra/rootfs/
```

4. Download the backup and restore patch file for PE1100N

   https://drive.google.com/file/d/13ncd179x_MB6-fYrm05OT7KIpm20B4v_/view?usp=sharing

5. Place the file PE1100N_backup_restore_patch.tar in the same directory as the Linux_for_Tegra folder

   ![圖片2](https://github.com/user-attachments/assets/1ca78490-9918-400a-8247-68c479036be2)

6. Overwrite the original SDK by patch files
```
$ tar xf PE1100N_backup_restore_patch.tar
$ sudo cp -r PE1100N_backup_restore_patch/Linux_for_Tegra/* Linux_for_Tegra
```

7. Applies the binaries to the rootfs.
```
$ cd Linux_for_Tegra
$ sudo ./ apply_binaries.sh
```

8. Create the backup image

   a. Enter Force Recovery Mode on the PE1100N   
      * Power off the PE1100N and remove the power cable.
      * Connect Host Computer and PE1100N Flash Port with Micro USB cable.
      * Press and hold the Force Recovery Button.
      * Connect the power cable and Power ON the PE1100N.
      * After 3s release the Force Recovery Button.

   b. Run this command from the Linux_for_Tegra folder on host PC:
      ```
      $ sudo ./PE1100N_backup.sh
      ```

      If this command completes successfully, a backup image is stored in **Linux_for_Tegra/tools/backup_restore/images.**

   c. After successful backup, you can manually reset the device.

9. Restore a PE1100N using a backup image

   a. Enter Force Recovery Mode on the PE1100N
      * Power off the PE1100N and remove the power cable.
      * onnect Host Computer and PE1100N Flash Port with Micro USB cable.
      * Press and hold the Force Recovery Button.
      * Connect the power cable and Power ON the PE1100N.
      * After 3s release the Force Recovery Button.

   b. Run this command from the Linux_for_Tegra folder on host PC:
      ```
      $ sudo ./PE1100N_restore.sh
      ```

   c. After successful restore, you can manually reset the device.

&nbsp;

## 5. OS and NVIDIA SDK Version Mapping Table

Please refer to the table below for recommended OS versions and NVIDIA SDK versions for each image version 
| PE1100N official release version | L4T | Ubuntu | JetPack | CUDA | DeepStream SDK | cuDNN | TensorRT |
| ------------- | ------------- | ------------- | ------------- | ------------- | ------------- | ------------- | ------------- |
| V1.0.0 | 35.3.1 | 20.04 | 5.1.1 | 11.4.19 | 6.2 | 8.6.0 | 8.5.2 |
| V1.1.1 | 35.4.1 | 20.04 | 5.1.2 | 11.4.19 | 6.3 | 8.6.0 | 8.5.2 |
| V2.0.5 | 36.3.0 | 22.04 | 6.0 | 12.2.2 | 6.4/7.0 |8.9.4 | 8.6.2 |
| V2.0.6 | 36.3.0 | 22.04 | 6.0 | 12.2.2 | 6.4/7.0 |8.9.4 | 8.6.2 |
| V2.0.7 | 36.4.0 | 22.04 | 6.1 | 12.6.10 | 7.1 | 9.3.0 | 10.3.0 |
| V2.0.11 | 36.4.3 | 22.04 | 6.2 | 12.6.10 | 7.1 | 9.3.0 | 10.3.0 |

&nbsp;

## 6. LTE Setting

### 6.1 How to set up a SIM card   
> NOTE : Please insert the SIM card and power on the device.
1. Click to open the settings bar at the top right side of the desktop.
![1](https://user-images.githubusercontent.com/97945168/231966032-dd9d8c75-10d2-4216-93fb-a8fc2821e20d.png)  

2. Click **Mobile Broadband Settings**
![2](https://user-images.githubusercontent.com/97945168/231969996-94c577b8-9da4-4745-b038-fc4dd97f890e.png)

3. **Switch on** the Mobile Broadband to enable LTE function   
![3](https://user-images.githubusercontent.com/97945168/231969834-b638a478-a641-451a-bd67-cc5efabaad10.png)

4. Open the Network bar below the IMEI
![4](https://user-images.githubusercontent.com/97945168/231970092-bce09542-34ce-4295-8630-d6d63a83d987.png)

5. Select **Add new connection**
![5](https://user-images.githubusercontent.com/97945168/231970265-283963c5-d8f7-409c-bb67-80a8031e06fc.png)

6. Click **Next** on the top right of the window
![6](https://user-images.githubusercontent.com/97945168/231970371-44229d11-56c5-415e-ac65-880ab5c233d0.png)

7. Select your country
![7](https://user-images.githubusercontent.com/97945168/231970488-5973f48e-468a-4267-9580-a3618c426136.png)

8. Select your provider
![8](https://user-images.githubusercontent.com/97945168/231970586-22849047-c3ef-480b-a8cc-21ddb1c4accd.png)

9. Select your plan
![9](https://user-images.githubusercontent.com/97945168/231970677-969024cb-710f-4cca-b50d-92ea9f8ca791.png)

10. Click **Apply** on the top right of the window
![10](https://user-images.githubusercontent.com/97945168/231970778-75142ec2-69f5-4b00-8d6c-ed6f9dc3eafb.png)

11. It will use this configure to connect to the internet automatically
![11](https://user-images.githubusercontent.com/97945168/231971724-31e3d906-5bdc-4b6f-906f-44204a14d7c8.png)

12. The current signal strength also appear on the settings bar
![12](https://user-images.githubusercontent.com/97945168/231971835-85c0f2f1-c064-44d8-98cb-2e4ae3e4348b.png)

&nbsp;

### 6.2 How to switch SIM card slot   
1. Open **Terminal** on the desktop
![1](https://user-images.githubusercontent.com/97945168/231972759-b07dd9ef-dfa4-40f6-a4ad-736fd3e5081d.png)

2. Type command `sudo PE1100N-config`, if it asks for a password, enter **the password set by yourself**. Press Enter.
![2](https://user-images.githubusercontent.com/97945168/231973109-07604154-afd0-4eec-a3b4-5911db6d80b8.png)

3. Select **Ok**
![3](https://user-images.githubusercontent.com/97945168/231974129-d9dc0023-ea0f-46d9-bfc3-e6f7163c980a.png)

4. Select **5. SIM  Select SIM slot** and press Enter
![4](https://user-images.githubusercontent.com/97945168/231974269-996aab6c-c21b-4b26-9e58-705a6991ee57.png)

5. Select **1 SIM1** or **2 SIM2** and press Enter
![5](https://user-images.githubusercontent.com/97945168/231974459-705e5ca4-6797-40b7-8c2d-022ef16e8bfd.png)

6. Select **Finish** and press Enter
![6](https://user-images.githubusercontent.com/97945168/231974758-1d0c422f-cb3d-4741-be44-b066ddb1af9f.png)

7. Select **Yes** and press Enter to reboot
![7](https://user-images.githubusercontent.com/97945168/231975016-df390260-279b-47e1-942d-d0d418970d74.png)

&nbsp;

### 6.3 How to check SIM card status
1. Open **Terminal** on the desktop
![1](https://user-images.githubusercontent.com/97945168/231976246-fc33ae07-2afa-4de0-ba26-04dd5853bf50.png)

2. Type command ‘`sudo PE1100N-config`’, if it asks for a password, enter **the password set by yourself**. Press Enter.
![2](https://user-images.githubusercontent.com/97945168/231976517-6e4a1891-d60f-46e7-8b56-00e726354a56.png)

3. Select **Ok**
![3](https://user-images.githubusercontent.com/97945168/231976656-41e2ff55-72ba-4d02-b017-2cef8b4de39c.png)

4. Select **7. Configuration** and press Enter
![4](https://user-images.githubusercontent.com/97945168/231976817-0439c251-038e-41c3-ac7a-2638db2743a6.png)

5. Check **SIM slot** and **SIM state** on the screen
![5](https://user-images.githubusercontent.com/97945168/231976999-69e6e0ff-740c-4ceb-8af4-067c97b437f4.png)

&nbsp;

## 7. Switching M.2, COM Mode, and SIM

1. Open Terminal on the desktop
2. Type command `sudo PE1100N-config`, if it asks for a password, enter the password set by yourself. Press Enter.

<img width="669" height="371" alt="Screenshot from 2025-07-23 14-29-00" src="https://github.com/user-attachments/assets/4076fdd4-5e67-46ec-9054-c4023e7f9f31" />

3. Select Ok

<img width="1182" height="569" alt="Screenshot from 2025-07-23 14-29-46" src="https://github.com/user-attachments/assets/03fa59f9-c293-45d4-a52d-ce4828cfb1d9" />

4. Select the M.2, COM Mode, and SIM you want to switch

<img width="1182" height="569" alt="Screenshot from 2025-07-23 14-31-55" src="https://github.com/user-attachments/assets/0fc6fd35-9707-4179-9292-2e304c672904" />

## 8. Switch DIO Instructions

1. Open Terminal on the desktop
2. Type below command to switch DIO

```
Set one DO Value: sudo dio_out #DO_Num # Value
Get one DI Value: sudo dio_in #DO_Num
Get all DO Value: sudo dio_out
Get all DI Value: sudo dio_in
```

## 9. LED Functions

### 9.1 Turn on/off LED

1. Open Terminal on the desktop
2. Below command are examples to turn on LED (Type Echo 1 or 0 for turning on/off LED)

```
ETH0 : sudo echo 1 > /sys/class/leds/eth0-led/brightness
ETH1: sudo echo 1 > /sys/class/leds/eth1-led/brightness
UART0: sudo echo 1 > /sys/class/leds/uart0-led/brightness
UART1: sudo echo 1 > /sys/class/leds/uart1-led/brightness
CAN: sudo echo 1 > /sys/class/leds/can-led/brightness
WIFI: sudo echo 1 > "/sys/class/leds/wifi-led/brightness
LTE: sudo echo 1 > /sys/class/leds/lte-led/brightness
```

### 9.2 Disable kernel LED function

1. Open Terminal on the desktop
2. Type below commands to disable kernel LED function

```
ETH0: sudo echo none > /sys/class/leds/eth0-led/trigger
ETH1: sudo echo none > /sys/class/leds/eth1-led/trigger
UART0: sudo echo none > /sys/class/leds/uart0-led/trigger
UART1: sudo echo none > /sys/class/leds/uart1-led/trigger
CAN: sudo echo none > /sys/class/leds/can-led/trigger
WIFI: sudo echo none > /sys/class/leds/wifi-led/trigger
LTE: sudo echo none > /sys/class/leds/lte-led/trigger
```

### 9.3 Recover Kernel LED function

1. Open Terminal on the desktop
2. Type below commands to recover kernel LED function

```
ETH0: sudo echo eth0 > /sys/class/leds/eth0-led/trigger
ETH1: sudo echo eth1 > /sys/class/leds/eth1-led/trigger
UART0: sudo echo uart0 > /sys/class/leds/uart0-led/trigger
UART1: : sudo echo uart1 > /sys/class/leds/uart1-led/trigger
CAN: sudo echo can > /sys/class/leds/can-led/trigger
WIFI: sudo echo wifi > /sys/class/leds/wifi-led/trigger
LTE: sudo echo lte > /sys/class/leds/lte-led/trigger
```

## 10. Others

### 10.1 ASUS API

[Asus_API_Programming_Guide_v1.05_20240223.pdf](https://github.com/ASUS-IPC/ASUS-IPC/files/14754133/Asus_API_Programming_Guide_v1.05_20240223.pdf)

[ASUS API (Library, Header files, Sample code)](https://github.com/ASUS-IPC/ASUS-IPC/files/14754156/asusapi_1.0.5-2_aarch64-linux-gnu.zip)

### 10.2 Get Console Log

**For PE1100N Box, the Console Port is the red box.**

![console port](https://github.com/user-attachments/assets/005e69fb-1e0b-4027-a71c-5f84d33280ad)

#### 10.2.1 Host PC : Windows
1. Connect PE1100N console port to a PC with Micro USB cable. 

   Open Device Manager on PC, **USB TO UART BRIDGE** may appear in Device Manager.

<img width="268" alt="pe1100n_otherdevices_2" src="https://github.com/user-attachments/assets/32b72e4e-14eb-4846-aae3-766094638177"/>  

2. In this case, you need to download the driver (F81232_231115_whql.zip) and update it.

[F81232_231115_whql.zip](https://github.com/ASUS-IPC/ASUS-IPC/files/15477566/F81232_231115_whql.zip)

![update driver](https://github.com/user-attachments/assets/483e9151-d669-41cb-9c7b-be45f180a052)

3. Install and open the PuTTY, select **Serial** and input the COM* and Speed is **115200**.

![setting](https://github.com/user-attachments/assets/ba5bbfb8-a38e-42e4-888f-d66efddec9c9)

4. Click the Open button on PuTTY and power on the PE1100N, and some boot logs will printed on PuTTY from PC. 



#### 10.2.2 Host PC : Ubuntu

1. Install minicom on Linux PC
```
sudo apt update
sudo apt install minicom
```

2. Connect Micro USB cable to the console port on PE1100N

3. Check if /dev/ttyUSB0 exists

4. Execute the script to capture logs [log_uart.zip](https://github.com/user-attachments/files/21115587/log_uart.zip)
```
sudo ./log_uart.sh
```
> If you want to exit minicom, press Ctrl+A, then press X.

5. The log will be generated in the uart_logs folder.


## 11. Demo : Intelligent Video Analytics

### 11.1 Metropolis Microservices for Jetson
NVIDIA Metropolis Microservices is a collection of software components designed for building intelligent video analytics applications. It's part of NVIDIA Metropolis, which is a platform aimed at transforming cities, enterprises, and industries into smart environments using computer vision, deep learning, and AI.

 Prerequisites
* Jetson Orin devices with JetPack 6.0 OS
* Android phone or tablet

1. Install Docker
```
sudo apt install -y docker.io
sudo usermod -aG docker $USER
newgrp docker
```
2. Install nvidia-jetson-services
```
sudo apt update
sudo apt install -y nvidia-jetson-services
```
3. Launch the Redis, Ingress and VST services
```
sudo systemctl start jetson-redis
sudo systemctl start jetson-ingress
sudo systemctl start jetson-vst
```
4. Download Jetson Platform Services Reference Workflow & Resources  

Follow the link below, and select on **Version History** tab  
Choose  1.1.0 -> Download  
https://catalog.ngc.nvidia.com/orgs/nvidia/teams/jps/resources/reference-workflow-and-resources
![圖片1](https://github.com/user-attachments/assets/c2370654-5522-4b67-81d8-d60f65a592c5)
**Note: 2.0.0 is for JetPack 6.1**

5. Launch NVStreamer  
```
unzip files.zip
rm files.zip
cd files
tar -xvf nvstreamer-1.1.0.tar.gz
cd nvstreamer
sudo docker compose -f compose_nvstreamer.yaml up -d --force-recreate
```
6. Launch AI_NVR  
```
cd <path of files>
tar -xvf ai_nvr-1.1.0.tar.gz
sudo cp ai_nvr/config/ai-nvr-nginx.conf /opt/nvidia/jetson/services/ingress/config/
cd ai_nvr
```
For Orin AGX:
```
sudo docker compose -f compose_agx.yaml up -d --force-recreate
```
For Orin NX 16G:
```
sudo docker compose -f compose_nx16.yaml up -d --force-recreate
```
For Orin NX 8G:
```
sudo docker compose -f compose_nx8.yaml up -d --force-recreate
```
For Orin Nano 8G/4G:
```
sudo docker compose -f compose_nano.yaml up -d --force-recreate
```
Docker containers will be created after executing the above instructions.  
![圖片2](https://github.com/user-attachments/assets/a5e10370-e99d-485e-8f24-5c05a230d9f8)

7. Visit the NVStream Streamer Dashboard  
 http://localhost:31000/  
![圖片4](https://github.com/user-attachments/assets/04f75362-871a-480f-9130-5faac38f315e)

Click "File Upload" and select sample_1080p_h264.mp4 from the files folder.  
![圖片5](https://github.com/user-attachments/assets/fac86427-eb09-4507-9e47-fea94327e944)

The file should appear on the dashboard once it has been uploaded successfully  
![圖片6](https://github.com/user-attachments/assets/02a59db4-8229-44dc-b992-a959ee2b65c1)

Ex: The RTSP URL is rtsp://192.168.1.46:31555/nvstream/root/store/nvstreamer_videos/sample_1080p_h264.mp4

8. Visit the VST Dashboard  
http://localhost:30080/vst  
![圖片7](https://github.com/user-attachments/assets/b785f885-fb80-47e0-99cf-b17152368de1)

Click “Sensor Management”, then add the device  
1. Enter the sample RTSP URL
2. Enter the sample name
3. Click submit  
![圖片8](https://github.com/user-attachments/assets/b9692ff9-05bf-4273-8929-a8d923145f8c)

The sample video should be listed on the VST Dashboard.  
![圖片9](https://github.com/user-attachments/assets/7caa821d-f4e0-4119-aa39-60b7f444ba8a)

9. Example for Metropolis analytics  
A. Go to http://localhost:30080/vst  
B. Click Live Streams.  
C. Select the sample VST.  
![圖片10](https://github.com/user-attachments/assets/217dc662-cee8-41de-9267-47ef8ba7e17b)  
D. Expand Analytics.  
![圖片11](https://github.com/user-attachments/assets/4b14c9d3-1a21-488f-989e-2d2bbb167a3f)  
E. Click “ROI”.  
![圖片12](https://github.com/user-attachments/assets/b0258b56-d198-4404-8348-b65d8834cc6b)  
F. Add areas of interest, then click “Done”  
![圖片13](https://github.com/user-attachments/assets/4f81fdbe-2c2a-4512-8689-5ee358585085)  
G. Enter “People” on the dialog, then click Submit  
![圖片14](https://github.com/user-attachments/assets/7fd34c23-e56d-4e7a-b471-17d65dfd9563)  
H. Select People on “Select ROIs”  
![圖片15](https://github.com/user-attachments/assets/adc0ba07-1b51-4b29-ab8a-87f4086252aa)  
I. Click “Show”  
![圖片16](https://github.com/user-attachments/assets/997ebfd5-c710-44e9-be9d-b7b2307ea6b4)  
J. Detected people will be displayed on the video screen.  
![圖片17](https://github.com/user-attachments/assets/21a17e97-a34d-4921-b34c-78b1ce0260fe)  

10. Download and install NVIDIA Jetson Services on Android phone or tablet  

Follow the link below, and there is an Android app that allows you to track events and create areas of interest to monitor  
you can find it on Google Play as AI NVR.  
https://play.google.com/store/apps/details?id=com.nvidia.ainvr  
![圖片18](https://github.com/user-attachments/assets/9d237ad5-7bb0-4331-93ab-0c81e6c91155)  

For **JetPack 6.0**, please download and install this version manually instead of the Play Store.  
https://apkpure.com/cn/jetson-platform-services/com.nvidia.ainvr/downloading/1.0.2024060601

11. Execute NVIDIA Jetson Services on Android device  

A. Enter the JETSON_IP address, then press “Submit”  
![圖片19](https://github.com/user-attachments/assets/5b709ff9-c1aa-4b39-a29d-97155b0ed168)  

B. Press “Analytics”  
![圖片20](https://github.com/user-attachments/assets/298c8dde-08e6-4c36-9bfa-5eef1f49f662)  

C. This App allows you to track events and create areas of interest to monitor  
![圖片21](https://github.com/user-attachments/assets/74bb4ed9-d5b5-490f-a7e4-2f4b93a70638)

Reference:
1. Tutorial mmj  
https://www.jetson-ai-lab.com/tutorial_mmj.html  
2. NVIDIA Metropolis Microservices  
https://developer.nvidia.com/metropolis-microservices
3. Overview of AI-NVR  
https://www.nvidia.com/zh-tw/on-demand/session/other2024-mmj2/

&nbsp;

### 11.2 Running DeepStream Python samples

1. Flash images for Jetpack 6.0  

Please follow the link below to flash the devices based on your models

For Orin NX 16G:  
https://dlcdnets.asus.com/pub/ASUS/mb/Embedded_IPC/PE1100N/PE1100N_JONXS_Orin-NX-16GB_JetPack-ssd-6.0.0_L4T-36.3.0_v2.0.6-official-20240904.tar.gz?model=PE1100N

For Orin NX 8G:  
https://dlcdnets.asus.com/pub/ASUS/mb/Embedded_IPC/PE1100N/PE1100N_JONXS_Orin-NX-8GB_JetPack-ssd-6.0.0_L4T-36.3.0_v2.0.6-official-20240904.tar.gz?model=PE1100N


For Orin Nano 8G:  
https://dlcdnets.asus.com/pub/ASUS/mb/Embedded_IPC/PE1100N/PE1100N_JONAS_Orin-Nano-8GB_JetPack-ssd-6.0.0_L4T-36.3.0_v2.0.6-official-20240904.tar.gz?model=PE1100N  

For Orin Nano 4G:  
https://dlcdnets.asus.com/pub/ASUS/mb/Embedded_IPC/PE1100N/PE1100N_JONAS_Orin-Nano-4GB_JetPack-ssd-6.0.0_L4T-36.3.0_v2.0.6-official-20240905.tar.gz?model=PE1100N  

2. Install Jetson Stats and use jtop to monitor the system
```
sudo apt-get update
sudo apt-get install python3-pip
sudo pip3 install -U jetson-stats
sudo reboot
jtop
```
![圖片1](https://github.com/user-attachments/assets/3f88961e-4900-4b09-bbe7-ee35507e10ea)  

**For more details, please follow the link below from NVIDIA developer website.**  
https://developer.nvidia.com/embedded/community/jetson-projects/jetson_stats  
  

2. Upgrade the compute stack to JetPack 6.1  
Please follow the link below to upgrade your device to Jetpack 6.1. If a release based on JetPack 6.1 is used, you can skip this.  
https://github.com/ASUS-IPC/ASUS-IPC/wiki/PE1100N#66-upgrade-to-jetpack-61  

3. Meet the prerequisites for the DeepStream SDK
```
sudo pip3 install meson
sudo pip3 install ninja
``` 

```
cd ~/Documents/
git clone https://github.com/GNOME/glib.git
cd glib
git checkout 2.76.6
meson build --prefix=/usr
ninja -C build/
cd build/
sudo ninja install
``` 

```
pkg-config --modversion glib-2.0
``` 

```
sudo apt install \
libssl3 \
libssl-dev \
libgstreamer1.0-0 \
gstreamer1.0-tools \
gstreamer1.0-plugins-good \
gstreamer1.0-plugins-bad \
gstreamer1.0-plugins-ugly \
gstreamer1.0-libav \
libgstreamer-plugins-base1.0-dev \
libgstrtspserver-1.0-0 \
libjansson4 \
libyaml-cpp-dev
```  
**For more details, please follow the link below from NVIDIA official website.**  
https://docs.nvidia.com/metropolis/deepstream/dev-guide/text/DS_Installation.html#prerequisites  

4. Install the DeepStream SDK  
```
cd ~/Documents/
wget --content-disposition 'https://api.ngc.nvidia.com/v2/resources/nvidia/deepstream/versions/7.1/files/deepstream-7.1_7.1.0-1_arm64.deb' -O deepstream-7.1_7.1.0-1_arm64.deb
sudo apt-get install ./deepstream-7.1_7.1.0-1_arm64.deb
wget --content-disposition 'https://github.com/NVIDIA-AI-IOT/deepstream_python_apps/releases/download/v1.2.0/pyds-1.2.0-cp310-cp310-linux_aarch64.whl' -O pyds-1.2.0-cp310-cp310-linux_aarch64.whl
sudo pip3 install pyds-1.2.0-cp310-cp310-linux_aarch64.whl
sudo pip3 install cuda-python
```  
**Please follow the links below for more information**  
https://docs.nvidia.com/metropolis/deepstream/dev-guide/text/DS_Installation.html#install-the-deepstream-sdk  
https://github.com/NVIDIA-AI-IOT/deepstream_python_apps/releases  
https://github.com/NVIDIA-AI-IOT/deepstream_python_apps/tree/master/bindings  

5. Download the DeepStream Python samples  
```
cd /opt/nvidia/deepstream/deepstream/sources/
sudo git clone https://github.com/NVIDIA-AI-IOT/deepstream_python_apps.git
```  

**Please follow the links below for more information**  
https://github.com/NVIDIA-AI-IOT/deepstream_python_apps  

6. Run the samples of the deepstream  
Before runing the samples, please run the following commads to boost the clocks  
```
sudo nvpmodel -m 0
sudo jetson_clocks
```  
**For more information, please refer to the following URL.**  
https://docs.nvidia.com/metropolis/deepstream/dev-guide/text/DS_Quickstart.html#boost-the-clocks  


* **Run the sample deepstream-test2**  
This is a sample with 4-class object detection, tracking and attribute classification pipeline.  
```
cd /opt/nvidia/deepstream/deepstream/sources/deepstream_python_apps/apps/deepstream-test2/
python3 deepstream_test_2.py /opt/nvidia/deepstream/deepstream/samples/streams/sample_720p.h264
```  

![圖片1](https://github.com/user-attachments/assets/dc51d858-7ec1-4042-9b9d-f33319236487)  
**For more information, please refer to the following URL.**  

https://github.com/NVIDIA-AI-IOT/deepstream_python_apps/tree/master/apps/deepstream-test2  
  

* **Run the sample deepstream-test3 with single file input**  
This is a sample with multi-stream pipeline performing 4-class object detection and also supports triton inference server, no-display mode, file-loop and silent mode.  
```
cd /opt/nvidia/deepstream/deepstream/sources/deepstream_python_apps/apps/deepstream-test3/
sudo python3 deepstream_test_3.py -i file:///opt/nvidia/deepstream/deepstream/samples/streams/sample_1080p_h264.mp4 -s --file-loop
```  
![圖片2](https://github.com/user-attachments/assets/30a2b6d7-d30c-42da-8136-0a7445dbc502)  


* **Run the sample deepstream-test3 with 4 file inputs**  
```
cd /opt/nvidia/deepstream/deepstream/sources/deepstream_python_apps/apps/deepstream-test3/
sudo python3 deepstream_test_3.py -i file:///opt/nvidia/deepstream/deepstream/samples/streams/sample_1080p_h264.mp4 file:///opt/nvidia/deepstream/deepstream/samples/streams/sample_1080p_h264.mp4 file:///opt/nvidia/deepstream/deepstream/samples/streams/sample_1080p_h264.mp4 file:///opt/nvidia/deepstream/deepstream/samples/streams/sample_1080p_h264.mp4 -s --file-loop
```
![圖片3](https://github.com/user-attachments/assets/6977803b-9264-46ee-bc13-7e4e6447461f)  

**For more information, please refer to the following URL.**  
https://github.com/NVIDIA-AI-IOT/deepstream_python_apps/tree/master/apps/deepstream-test3  

&nbsp;

### 11.3 Visual Language Models (VLM) for Jetson  

VLMs are multi modal models supporting images, video and text and using a combination of large language models and vision transformers. Based on this capability, they are able to support text prompts to query videos and images thereby enabling capabilities such as chatting with the video, and defining natural language based alerts.  

 Prerequisites
* Jetson Orin devices with JetPack 6.0 OS
* Android phone or tablet  

1. Install Docker
```
sudo apt install -y docker.io
sudo usermod -aG docker $USER
newgrp docker
```  
2. Install nvidia-jetson-services
```
sudo apt update
sudo apt install -y nvidia-jetson-services
```  
3. Launch the VST services
```
sudo systemctl start jetson-vst
```  
4. Download Jetson Platform Services Reference Workflow & Resources  

Follow the link below, and select on **Version History** tab  
Choose  1.1.0 -> Download  
https://catalog.ngc.nvidia.com/orgs/nvidia/teams/jps/resources/reference-workflow-and-resources
![圖片1](https://github.com/user-attachments/assets/c2370654-5522-4b67-81d8-d60f65a592c5)
**Note: 2.0.0 is for JetPack 6.1**  

5. Launch NVStreamer  
```
unzip files.zip
rm files.zip
cd files
tar -xvf nvstreamer-1.1.0.tar.gz
cd nvstreamer
sudo docker compose -f compose_nvstreamer.yaml up -d --force-recreate
```  

6. Visit the NVStream Streamer Dashboard  
 http://localhost:31000/  
![圖片4](https://github.com/user-attachments/assets/04f75362-871a-480f-9130-5faac38f315e)  

Click "File Upload" and select sample_1080p_h264.mp4 from the files folder.  
![圖片5](https://github.com/user-attachments/assets/fac86427-eb09-4507-9e47-fea94327e944)  

The file should appear on the dashboard once it has been uploaded successfully  
![圖片6](https://github.com/user-attachments/assets/02a59db4-8229-44dc-b992-a959ee2b65c1)  
Ex: The RTSP URL is rtsp://192.168.1.46:31555/nvstream/root/store/nvstreamer_videos/sample_1080p_h264.mp4  

7. Visit the VST Dashboard  
http://localhost:30080/vst  
![圖片7](https://github.com/user-attachments/assets/b785f885-fb80-47e0-99cf-b17152368de1)  

Click “Sensor Management”, then add the device  
1. Enter the sample RTSP URL
2. Enter the sample name
3. Click submit  
![圖片8](https://github.com/user-attachments/assets/b9692ff9-05bf-4273-8929-a8d923145f8c)  

The sample video should be listed on the VST Dashboard.  
![圖片9](https://github.com/user-attachments/assets/7caa821d-f4e0-4119-aa39-60b7f444ba8a)  

8. Launch VLM  
```
cd <path of files>
tar -xvf vlm-1.1.0.tar.gz
cd vlm/example_1
sudo cp config/vlm-nginx.conf /opt/nvidia/jetson/services/ingress/config
sudo cp config/prometheus.yml /opt/nvidia/jetson/services/monitoring/config/prometheus.yml
sudo cp config/rules.yml /opt/nvidia/jetson/services/monitoring/config/rules.yml
```  

Start the foundation services and launch it.
```
sudo systemctl start jetson-ingress
sudo systemctl start jetson-monitoring
sudo systemctl start jetson-sys-monitoring
sudo systemctl start jetson-gpu-monitoring
sudo docker compose up -d
```  
The first time the VLM service is launched, it will automatically download and quantize the VLM. This will take some time.  
You can visit the page http://JETSON_IP:5015/v1/health, If the VLM is ready it will return (“detail”:”ready”). If you are launching the VLM for the first time it will take some time to fully load.  
![1](https://github.com/user-attachments/assets/ecd3af77-2778-46af-b93c-a3ba5d771205)  
**Important** If it shows (“detail”:”model loading”), it means it is not ready yet.  
![2](https://github.com/user-attachments/assets/da890011-0583-4738-a6cc-afd4eb1a6f48)  

9. Interact with VLM Service  
A. Control Stream Input via REST APIs  
You can start by adding an RTSP stream for the VLM to use with the following curl command. This will use the POST method on the live-stream endpoint. Currently the VLM will only support 1 stream but in the future this API will allow for multi-stream support.  

Replace 192.168.100.45 with your Jetson IP and replace the RTSP link with your RTSP link.  
```
curl --location 'http://192.168.100.45:5010/api/v1/live-stream' \
--header 'Content-Type: application/json' \
--data '{
"liveStreamUrl":"rtsp://192.168.100.45:31554/nvstream/root/store/nvstreamer_videos/sample_1080p_h264.mp4"
}'
```  

This request will return a unique stream ID that is used later to set alerts and ask follow up questions and remove the stream.
Ex: "id": "f16ffb43-95a4-44c5-bc5f-00cad33ddaf2"  
![3](https://github.com/user-attachments/assets/44d5f78f-d887-4494-83e1-f89edfe6fd2a)  
  
B. Set Alerts  
Alerts are questions that the VLM will continuously evaluate on the live stream input. For each alert rule set, the VLM will try to decide if it is True or False based on the most recent frame from of the live stream. These True and False states as determined by the VLM, are sent to a websocket and the jetson monitoring service.  

When setting alerts, the alert rule should be phrased as a yes/no question. Such as “Is there people?”. The body of the request must also have the “id” field that corresponds to the stream ID that was returned when the RTSP stream was added.  
```
curl --location 'http://192.168.100.45:5010/api/v1/alerts' \
--header 'Content-Type: application/json' \
--data '{
    "alerts": ["is there people?"],
    "id": "f16ffb43-95a4-44c5-bc5f-00cad33ddaf2"
}'
```  

C. View RTSP Stream Output  
Once a stream is added, it will be passed through to the output RTSP stream. You can view this stream at "rtsp://JETSON_IP:5011/out". Once a query or alert is added, we can view the VLM responses on this output stream.  
Ex: You can view this RTSP stream by VLC  
![4](https://github.com/user-attachments/assets/3a0774b7-fccc-4ec3-87ca-69b8b977a3fa)  

D. Delete the stream  
To shut down the example you can first remove the stream using a DELETE method on the live-stream endpoint. Note the stream ID is added to the URL path for this.
```
curl --location --request DELETE 'http://192.168.100.45:5010/api/v1/live-stream/f16ffb43-95a4-44c5-bc5f-00cad33ddaf2'
```
This request will return “Stream removed successfully”  
![5](https://github.com/user-attachments/assets/24d6a15b-953d-4543-9bf6-c5494159e231)  

10. Using VLM Service from Android phone  
A. Download and install NVIDIA Jetson Services on Android phone or tablet  

Follow the link below, and there is an Android app that allows you to track events and create areas of interest to monitor  
you can find it on Google Play as AI NVR.  
https://play.google.com/store/apps/details?id=com.nvidia.ainvr  
![圖片18](https://github.com/user-attachments/assets/9d237ad5-7bb0-4331-93ab-0c81e6c91155)  

For **JetPack 6.0**, please download and install this version manually instead of the Play Store.  
https://apkpure.com/cn/jetson-platform-services/com.nvidia.ainvr/downloading/1.0.2024060601  

B. Execute NVIDIA Jetson Services on Android device  
Enter the JETSON_IP address, then press “Submit”  
![圖片19](https://github.com/user-attachments/assets/5b709ff9-c1aa-4b39-a29d-97155b0ed168)  

Press message button.  
![6](https://github.com/user-attachments/assets/69bf3ec9-b60c-4449-bc78-f67f5b1f74c8)  

Now you can talk to the VLM service. For example, ask VLM what he sees on the screen.  
![7](https://github.com/user-attachments/assets/2c76a61f-cbdc-4c2a-bae2-a7de5f66d6c3)

**Reference**  
Visual Language Models (VLM) with Jetson Platform Services  
https://docs.nvidia.com/jetson/jps/inference-services/vlm.html

&nbsp;

## 12. Device Management - AICC

With ASUS IoT Cloud Console (AICC), you can manage PE1100N with simple steps, know the device information, online status, modify profile settings and deploy applications remotely, any modifications can be synced in real time.

**Feature**

- Device Management

   View online/offline information. Monitor CPU, memory, storage and usage information. Power off or restart devices. 

- APP Management

   Install or uninstall apps. Monitor app information.

- Sensor-data monitor

   Data acquisition, visualization and monitoring.

- Notifications

   The real-time detection and alarm system allows managers to know the status of devices at anytime and anywhere.

- Remote Command

   The Command feature enables administrators to manage devices remotely, including troubleshooting and information gathering. 

More information https://iot.asus.com/solutions/asus-iot-cloud-console-aicc/

<img width="553" height="314" alt="圖片9" src="https://github.com/user-attachments/assets/790c20b2-7802-40d1-9f9b-675823b1a7bb" />














 









